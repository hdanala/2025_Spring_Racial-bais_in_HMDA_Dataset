{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df694edc-3c8e-4c0b-a6a5-bb3f95a306d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HMDA Lending Bias Analysis\n",
    "# This script analyzes HMDA data across multiple states to explore lending bias by race.\n",
    "# It includes data preprocessing, visualizations, regression models, and fairness metrics.import pandas as pd\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import statsmodels.api as sm\n",
    "from imblearn.over_sampling import SMOTE\n",
    "# Set up the path to save visualizations\n",
    "downloads_path = r\"C:\\Users\\chall\\OneDrive\\Documents\"\n",
    "os.makedirs(downloads_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa0792e7-d9d6-4b6d-a204-d9423fa77dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial dataset size: 1133037 rows\n",
      "Initial columns: ['activity_year', 'lei', 'derived_msa-md', 'state_code', 'county_code', 'census_tract', 'conforming_loan_limit', 'derived_loan_product_type', 'derived_dwelling_category', 'derived_ethnicity', 'derived_race', 'derived_sex', 'action_taken', 'purchaser_type', 'preapproval', 'loan_type', 'loan_purpose', 'lien_status', 'reverse_mortgage', 'open-end_line_of_credit', 'business_or_commercial_purpose', 'loan_amount', 'loan_to_value_ratio', 'interest_rate', 'rate_spread', 'hoepa_status', 'total_loan_costs', 'total_points_and_fees', 'origination_charges', 'discount_points', 'lender_credits', 'loan_term', 'prepayment_penalty_term', 'intro_rate_period', 'negative_amortization', 'interest_only_payment', 'balloon_payment', 'other_nonamortizing_features', 'property_value', 'construction_method', 'occupancy_type', 'manufactured_home_secured_property_type', 'manufactured_home_land_property_interest', 'total_units', 'multifamily_affordable_units', 'income', 'debt_to_income_ratio', 'applicant_credit_score_type', 'co-applicant_credit_score_type', 'applicant_ethnicity-1', 'applicant_ethnicity-2', 'applicant_ethnicity-3', 'applicant_ethnicity-4', 'applicant_ethnicity-5', 'co-applicant_ethnicity-1', 'co-applicant_ethnicity-2', 'co-applicant_ethnicity-3', 'co-applicant_ethnicity-4', 'co-applicant_ethnicity-5', 'applicant_ethnicity_observed', 'co-applicant_ethnicity_observed', 'applicant_race-1', 'applicant_race-2', 'applicant_race-3', 'applicant_race-4', 'applicant_race-5', 'co-applicant_race-1', 'co-applicant_race-2', 'co-applicant_race-3', 'co-applicant_race-4', 'co-applicant_race-5', 'applicant_race_observed', 'co-applicant_race_observed', 'applicant_sex', 'co-applicant_sex', 'applicant_sex_observed', 'co-applicant_sex_observed', 'applicant_age', 'co-applicant_age', 'applicant_age_above_62', 'co-applicant_age_above_62', 'submission_of_application', 'initially_payable_to_institution', 'aus-1', 'aus-2', 'aus-3', 'aus-4', 'aus-5', 'denial_reason-1', 'denial_reason-2', 'denial_reason-3', 'denial_reason-4', 'tract_population', 'tract_minority_population_percent', 'ffiec_msa_md_median_family_income', 'tract_to_msa_income_percentage', 'tract_owner_occupied_units', 'tract_one_to_four_family_homes', 'tract_median_age_of_housing_units', 'state']\n"
     ]
    }
   ],
   "source": [
    "# Load and concatenate state-level HMDA data with corrected state assignments\n",
    "co_data = pd.read_csv(\n",
    "    r\"C:\\Users\\chall\\Downloads\\state_CO_actions_taken_1-3-6-7_races_American Indian or Alaska Native-Asian-Black or African America6bc2eb02ff70040dfa7acab9a25eb91a.csv\",\n",
    "    low_memory=False\n",
    ").assign(state=\"CO\")\n",
    "mo_data = pd.read_csv(\n",
    "    r\"C:\\Users\\chall\\Downloads\\state_MO_actions_taken_1-3-5-6-7_races_American Indian or Alaska Native-Black or African American-Whcf47184be226fb25a036db6bb872aa86.csv\",\n",
    "    low_memory=False\n",
    ").assign(state=\"MO\")\n",
    "ca_data = pd.read_csv(\n",
    "    r\"C:\\Users\\chall\\Downloads\\state_TX_actions_taken_1-3-5-6-7_races_American Indian or Alaska Native-Black or African American-Wh7ac0aaa84940e60ea778e85a981eaaf4.csv\",\n",
    "    low_memory=False\n",
    ").assign(state=\"TX\")\n",
    "tx_data = pd.read_csv(\n",
    "    r\"C:\\Users\\chall\\Downloads\\state_California_actions_taken_1-2-3-5-6-7_races_American Indian or Alaska Native-Black or African American-e5491824502a69096e36340f3a48da1a.csv\",\n",
    "    low_memory=False\n",
    ").assign(state=\"CA\")\n",
    "df = pd.concat([co_data, mo_data, ca_data, tx_data], ignore_index=True)\n",
    "print(f\"Initial dataset size: {len(df)} rows\")\n",
    "print(\"Initial columns:\", df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d03751a8-5c84-4676-af5e-4c3cb3e8ca25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only the columns we need\n",
    "columns_to_keep = ['income', 'loan_amount', 'action_taken', 'census_tract', 'derived_race', 'state_code', 'state']\n",
    "df = df[columns_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2b00b22-0c6b-4ee9-a31f-03e8a2b7bf47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with missing state_code, race, or action_taken\n",
    "df = df.dropna(subset=['state_code', 'derived_race', 'action_taken'])\n",
    "df['state_code'] = df['state_code'].astype(str)\n",
    "df['derived_race'] = df['derived_race'].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c18a5404-ffff-481f-9af3-7a0b077e31cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up any 'nan' strings\n",
    "df['state_code'] = df['state_code'].replace('nan', np.nan)\n",
    "df['derived_race'] = df['derived_race'].replace('nan', np.nan)\n",
    "df = df.dropna(subset=['state_code', 'derived_race'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d3a1378-e8de-476c-973e-5298689c94dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "States after mapping: ['Colorado' 'Missouri' 'Texas' 'California']\n"
     ]
    }
   ],
   "source": [
    "# Map state codes to full names\n",
    "state_mapping = {\"CO\": \"Colorado\", \"MO\": \"Missouri\", \"CA\": \"California\", \"TX\": \"Texas\"}\n",
    "df['state_code'] = df['state_code'].map(state_mapping)\n",
    "print(\"States after mapping:\", df['state_code'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9433cb2-637e-49f1-b771-6b40dbcfa23d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Races: ['White' 'American Indian or Alaska Native' 'Black or African American'\n",
      " 'Asian' '2 or more minority races']\n",
      "Action taken values: [1 3 6 7 5 2]\n"
     ]
    }
   ],
   "source": [
    "# Ensure action_taken is numeric\n",
    "df['action_taken'] = pd.to_numeric(df['action_taken'], errors='coerce')\n",
    "df = df.dropna(subset=['action_taken'])\n",
    "df['action_taken'] = df['action_taken'].astype(int)\n",
    "print(\"Races:\", df['derived_race'].unique())\n",
    "print(\"Action taken values:\", df['action_taken'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75c38ed5-c11b-45bb-8785-c6bc6f566d83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing income values: 20379\n",
      "Missing loan_amount values: 0\n"
     ]
    }
   ],
   "source": [
    "# Convert income and loan_amount to numeric\n",
    "df['income'] = pd.to_numeric(df['income'], errors='coerce')\n",
    "df['loan_amount'] = pd.to_numeric(df['loan_amount'], errors='coerce')\n",
    "print(\"Missing income values:\", df['income'].isna().sum())\n",
    "print(\"Missing loan_amount values:\", df['loan_amount'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32e54160-db60-479a-80f7-f6d6b6fb99b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop states where income or loan_amount are all NaN\n",
    "state_nan_check = df.groupby('state_code')[['income', 'loan_amount']].apply(lambda x: x.isna().all())\n",
    "states_to_drop = state_nan_check[(state_nan_check['income'] == True) | (state_nan_check['loan_amount'] == True)].index.tolist()\n",
    "if states_to_drop:\n",
    "    print(f\"Dropping states with all NaN income/loan_amount: {states_to_drop}\")\n",
    "    df = df[~df['state_code'].isin(states_to_drop)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72618e8b-11e5-4353-b34b-0fcdf584d78c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing income after filling: 0\n",
      "Missing loan_amount after filling: 0\n"
     ]
    }
   ],
   "source": [
    "# Fill missing income and loan_amount with state-wise medians\n",
    "df['income'] = df.groupby('state_code')['income'].transform(lambda x: x.fillna(x.median()))\n",
    "df['loan_amount'] = df.groupby('state_code')['loan_amount'].transform(lambda x: x.fillna(x.median()))\n",
    "print(\"Missing income after filling:\", df['income'].isna().sum())\n",
    "print(\"Missing loan_amount after filling:\", df['loan_amount'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc9cb7ee-b252-4e68-8c76-42332e93aa28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size after cleaning: 1133037\n",
      "Income type: float64\n",
      "Loan amount type: float64\n"
     ]
    }
   ],
   "source": [
    "# Drop any remaining rows with NaNs\n",
    "df = df.dropna(subset=['income', 'loan_amount'])\n",
    "print(\"Dataset size after cleaning:\", len(df))\n",
    "\n",
    "# Verify income and loan_amount are numeric\n",
    "if not (df['income'].dtype in [np.float64, np.int64] and df['loan_amount'].dtype in [np.float64, np.int64]):\n",
    "    raise ValueError(\"Income or loan_amount is not numeric after cleaning\")\n",
    "print(\"Income type:\", df['income'].dtype)\n",
    "print(\"Loan amount type:\", df['loan_amount'].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9cf10dfc-6b5c-4b1d-8ad6-3c872f06d319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action taken after mapping: [1 0]\n"
     ]
    }
   ],
   "source": [
    "# Convert action_taken to binary: 1 = approved, 0 = denied\n",
    "df['action_taken'] = df['action_taken'].apply(lambda x: 1 if x == 1 else 0)\n",
    "print(\"Action taken after mapping:\", df['action_taken'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61133a9c-6224-4e55-8a16-d4b4a5851d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size after race simplification: 1126535 rows\n",
      "Races after simplification: ['White' 'Other' 'Black or African American' '2 or more minority races']\n"
     ]
    }
   ],
   "source": [
    "# Simplify race categories\n",
    "df = df[~df['derived_race'].isin(['Asian', 'Joint', 'Free Form Text Only', 'Race Not Available'])]\n",
    "df.loc[df['derived_race'].isin(['American Indian or Alaska Native', 'Native Hawaiian or Other Pacific Islander']), 'derived_race'] = 'Other'\n",
    "print(f\"Dataset size after race simplification: {len(df)} rows\")\n",
    "print(\"Races after simplification:\", df['derived_race'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "19813ab0-1081-4b59-928a-6865c403b71e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-minority tracts: 0\n"
     ]
    }
   ],
   "source": [
    "# Flag high-minority census tracts\n",
    "df['census_tract'] = df['census_tract'].astype(str)\n",
    "df['high_minority_tract'] = (df['census_tract'].str[-4:].astype(float) > 5000).astype(int)\n",
    "print(f\"High-minority tracts: {df['high_minority_tract'].sum()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5906c0d5-92ed-4fc4-b35e-e7bc0dca7f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Approval Rates by Race and State\n",
    "df['approved'] = df['action_taken']\n",
    "approval_rates = df.groupby(['state_code', 'derived_race'])['approved'].mean().reset_index()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x='state_code', y='approved', hue='derived_race', data=approval_rates, palette=['tab:blue', 'tab:orange', 'lightgray', 'darkgray'])\n",
    "plt.title('Loan Approvals by Race and State', fontsize=20)\n",
    "plt.xlabel('State', fontsize=18)\n",
    "plt.ylabel('Approval Rate', fontsize=20)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "# Place legend on the left side\n",
    "plt.legend(title='Race', fontsize=14, title_fontsize=14, loc='center left', bbox_to_anchor=(-0.3, 0.5))\n",
    "plt.subplots_adjust(left=0.25, right=0.95, top=0.9, bottom=0.1)\n",
    "plt.savefig(os.path.join(downloads_path, 'loan_approvals_by_race_state.png'))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c91582ee-453e-4b95-9ac2-f91cf94072af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Income and Loan Amount by Approval Status\n",
    "combined_means = df.groupby(['state_code', 'approved'])[['income', 'loan_amount']].mean().reset_index()\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(14, 6))\n",
    "# Income on left y-axis\n",
    "sns.barplot(x='state_code', y='income', hue='approved', data=combined_means, palette=['tab:blue', 'tab:orange'], ax=ax1, alpha=0.8, width=0.4)\n",
    "ax1.set_xlabel('State', fontsize=18)\n",
    "ax1.set_ylabel('Average Income', fontsize=18, color='tab:blue', labelpad=20)\n",
    "ax1.tick_params(axis='y', labelcolor='tab:blue', labelsize=14)\n",
    "ax1.set_title('Average Income and Loan Amount by Approval Status Across States', fontsize=20, pad=25)\n",
    "\n",
    "# Loan amount on right y-axis\n",
    "ax2 = ax1.twinx()\n",
    "sns.barplot(x='state_code', y='loan_amount', hue='approved', data=combined_means, palette=['tab:blue', 'tab:orange'], ax=ax2, alpha=0.4, width=0.4)\n",
    "ax2.set_ylabel('Average Loan Amount', fontsize=18, color='tab:orange', labelpad=20)\n",
    "ax2.tick_params(axis='y', labelcolor='tab:orange', labelsize=14)\n",
    "\n",
    "# Manage legends to avoid duplicates and place on the left\n",
    "ax1.get_legend().remove()\n",
    "handles, labels = ax2.get_legend_handles_labels()\n",
    "fig.legend(handles[:2], ['Approved (Yes)', 'Denied (No)'], title='Approval Status', fontsize=14, title_fontsize=14, \n",
    "           loc='center left', bbox_to_anchor=(-0.3, 0.5))\n",
    "ax2.get_legend().remove()\n",
    "\n",
    "plt.xticks(fontsize=14)\n",
    "plt.subplots_adjust(left=0.25, right=0.85, top=0.9, bottom=0.1)\n",
    "plt.savefig(os.path.join(downloads_path, 'income_and_loan_amount_by_approval.png'))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6ca6bfb3-dbd0-49fa-ba31-f296e13a58f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size for OLS: 1126535\n"
     ]
    }
   ],
   "source": [
    "# OLS Regression for Approval Analysis\n",
    "df_ols = df.copy()\n",
    "df_ols['income'] = pd.to_numeric(df_ols['income'], errors='coerce')\n",
    "df_ols['loan_amount'] = pd.to_numeric(df_ols['loan_amount'], errors='coerce')\n",
    "df_ols['action_taken'] = df_ols['action_taken'].astype(int)\n",
    "df_ols['high_minority_tract'] = df_ols['high_minority_tract'].astype(int)\n",
    "\n",
    "df_ols = df_ols.dropna(subset=['income', 'loan_amount'])\n",
    "print(\"Dataset size for OLS:\", len(df_ols))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "997c49bd-ba88-405d-a907-69fac142807a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummy variables for race and state\n",
    "df_ols = pd.get_dummies(df_ols, columns=['derived_race', 'state_code'], drop_first=True, dtype=np.uint8)\n",
    "dummy_cols = [col for col in df_ols.columns if col.startswith('derived_race_') or col.startswith('state_code_')]\n",
    "for col in dummy_cols:\n",
    "    df_ols[col] = pd.to_numeric(df_ols[col], errors='coerce').astype(np.uint8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3fc5add9-833b-4e2b-988a-c492379a9289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features for OLS\n",
    "features = ['income', 'loan_amount', 'high_minority_tract'] + dummy_cols\n",
    "X_ols = df_ols[features]\n",
    "X_ols = sm.add_constant(X_ols)\n",
    "y_ols = df_ols['action_taken']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a0f0e6f9-631b-4340-b56b-b6bd64f42121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OLS Results:\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:           action_taken   R-squared:                       0.025\n",
      "Model:                            OLS   Adj. R-squared:                  0.025\n",
      "Method:                 Least Squares   F-statistic:                     3591.\n",
      "Date:                Sun, 04 May 2025   Prob (F-statistic):               0.00\n",
      "Time:                        16:50:48   Log-Likelihood:            -7.3233e+05\n",
      "No. Observations:             1126535   AIC:                         1.465e+06\n",
      "Df Residuals:                 1126526   BIC:                         1.465e+06\n",
      "Df Model:                           8                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==========================================================================================================\n",
      "                                             coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "const                                      0.4694      0.007     69.234      0.000       0.456       0.483\n",
      "income                                 -2.423e-08   4.91e-08     -0.493      0.622   -1.21e-07    7.21e-08\n",
      "loan_amount                              9.54e-08   9.03e-10    105.615      0.000    9.36e-08    9.72e-08\n",
      "high_minority_tract                    -9.688e-17   3.84e-18    -25.220      0.000   -1.04e-16   -8.94e-17\n",
      "derived_race_Black or African American     0.0534      0.007      7.744      0.000       0.040       0.067\n",
      "derived_race_Other                         0.0043      0.008      0.556      0.578      -0.011       0.019\n",
      "derived_race_White                         0.1547      0.007     22.851      0.000       0.141       0.168\n",
      "state_code_Colorado                        0.1255      0.001     84.504      0.000       0.123       0.128\n",
      "state_code_Missouri                        0.0968      0.002     63.902      0.000       0.094       0.100\n",
      "state_code_Texas                           0.0146      0.001     14.259      0.000       0.013       0.017\n",
      "==============================================================================\n",
      "Omnibus:                   365621.474   Durbin-Watson:                   1.066\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):          9839427.523\n",
      "Skew:                          -0.983   Prob(JB):                         0.00\n",
      "Kurtosis:                      17.344   Cond. No.                     5.27e+22\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 1.33e-28. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "# Run OLS regression\n",
    "ols_model = sm.OLS(y_ols, X_ols).fit()\n",
    "print(\"OLS Results:\")\n",
    "print(ols_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bc682ef1-12cd-49ab-a462-539ff82ae78a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size for logistic regression: 1126535\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression and Bias Analysis\n",
    "df_lr = df.copy()\n",
    "df_lr['income'] = pd.to_numeric(df_lr['income'], errors='coerce')\n",
    "df_lr['loan_amount'] = pd.to_numeric(df_lr['loan_amount'], errors='coerce')\n",
    "df_lr['action_taken'] = df_lr['action_taken'].astype(int)\n",
    "df_lr['high_minority_tract'] = df_lr['high_minority_tract'].astype(int)\n",
    "\n",
    "df_lr = df_lr.dropna(subset=['income', 'loan_amount'])\n",
    "print(\"Dataset size for logistic regression:\", len(df_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "57831dd6-aff5-4292-917b-d8b8b46a6bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummy variables\n",
    "df_lr = pd.get_dummies(df_lr, columns=['derived_race', 'state_code'], drop_first=True, dtype=np.uint8)\n",
    "dummy_cols_lr = [col for col in df_lr.columns if col.startswith('derived_race_') or col.startswith('state_code_')]\n",
    "for col in dummy_cols_lr:\n",
    "    df_lr[col] = pd.to_numeric(df_lr[col], errors='coerce').astype(np.uint8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6371fd-f4f0-4fc3-92a0-cb57243744cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features and target\n",
    "features_lr = ['income', 'loan_amount', 'high_minority_tract'] + dummy_cols_lr\n",
    "X = df_lr[features_lr]\n",
    "y = df_lr['action_taken']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ace0bbf-5038-4e5a-9e48-db9d225cb115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data, ensuring race stratification\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=df.loc[X.index, 'derived_race'])\n",
    "print(\"Race distribution in test set:\", df.loc[X_test.index, 'derived_race'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12298134-a163-4ed2-83b9-195c3ef7cbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply SMOTE to handle class imbalance\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03c3594-fb0b-4632-8d97-f51601b9076e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train logistic regression model\n",
    "model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "model.fit(X_train_smote, y_train_smote)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c420fe62-1b02-4b9d-9f5b-e6692bf3e9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix visualization\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=sns.color_palette(['tab:blue', 'tab:red'], as_cmap=True),\n",
    "            xticklabels=[\"Denied\", \"Approved\"], yticklabels=[\"Denied\", \"Approved\"])\n",
    "plt.title('Model Prediction Accuracy (Confusion Matrix)', fontsize=16)\n",
    "plt.xlabel('Predicted', fontsize=14)\n",
    "plt.ylabel('Actual', fontsize=14)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(downloads_path, \"model_prediction_accuracy.png\"))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b81f108-5ed9-4d20-bcf1-62be6ec16df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare actual vs predicted approval rates by race\n",
    "X_test_reset = X_test.reset_index(drop=True)\n",
    "y_test_reset = pd.Series(y_test, name='action_taken').reset_index(drop=True)\n",
    "y_pred_reset = pd.Series(y_pred, name='predicted').reset_index(drop=True)\n",
    "test_indices = X_test.index\n",
    "race_data = df.loc[test_indices, 'derived_race'].reset_index(drop=True)\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    'derived_race': race_data,\n",
    "    'actual': y_test_reset,\n",
    "    'predicted': y_pred_reset\n",
    "})\n",
    "\n",
    "actual_rates = results_df.groupby('derived_race')['actual'].mean().reset_index()\n",
    "actual_rates.columns = ['derived_race', 'actual_approval_rate']\n",
    "predicted_rates = results_df.groupby('derived_race')['predicted'].mean().reset_index()\n",
    "predicted_rates.columns = ['derived_race', 'predicted_approval_rate']\n",
    "approval_rates_df = pd.merge(actual_rates, predicted_rates, on='derived_race')\n",
    "\n",
    "approval_rates_melted = approval_rates_df.melt(id_vars='derived_race',\n",
    "                                               value_vars=['actual_approval_rate', 'predicted_approval_rate'],\n",
    "                                               var_name='Rate Type', value_name='Approval Rate')\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='derived_race', y='Approval Rate', hue='Rate Type', data=approval_rates_melted, palette=['tab:blue', 'tab:orange'])\n",
    "plt.title('Actual vs Predicted Loan Approvals by Race', fontsize=16)\n",
    "plt.xlabel('Race', fontsize=14)\n",
    "plt.ylabel('Approval Rate', fontsize=14)\n",
    "plt.xticks(rotation=45, fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "# Place legend on the left side\n",
    "plt.legend(title='Rate Type (Actual vs Predicted)', fontsize=14, title_fontsize=14, loc='center left', bbox_to_anchor=(-0.3, 0.5))\n",
    "plt.subplots_adjust(left=0.25, right=0.95, top=0.9, bottom=0.2)\n",
    "plt.savefig(os.path.join(downloads_path, 'actual_vs_predicted_approvals_by_race.png'))\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24155bb-840f-4d52-bb62-f3d6af535a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fairness Metrics\n",
    "def calculate_eod(df, group_col, actual_col, pred_col, groups):\n",
    "    tpr_diff = 0\n",
    "    fpr_diff = 0\n",
    "    for group in groups:\n",
    "        group_data = df[df[group_col] == group]\n",
    "        tp = len(group_data[(group_data[actual_col] == 1) & (group_data[pred_col] == 1)])\n",
    "        fn = len(group_data[(group_data[actual_col] == 1) & (group_data[pred_col] == 0)])\n",
    "        tpr = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        fp = len(group_data[(group_data[actual_col] == 0) & (group_data[pred_col] == 1)])\n",
    "        tn = len(group_data[(group_data[actual_col] == 0) & (group_data[pred_col] == 0)])\n",
    "        fpr = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "        df.loc[df[group_col] == group, 'TPR'] = tpr\n",
    "        df.loc[df[group_col] == group, 'FPR'] = fpr\n",
    "    tpr_diff = df['TPR'].max() - df['TPR'].min()\n",
    "    fpr_diff = df['FPR'].max() - df['FPR'].min()\n",
    "    return max(tpr_diff, fpr_diff)\n",
    "\n",
    "racial_groups = ['White', 'Black or African American', '2 or more minority races', 'Other']\n",
    "eod = calculate_eod(results_df, 'derived_race', 'actual', 'predicted', racial_groups)\n",
    "print(f\"Equalized Odds Difference (EOD): {eod:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbdff94-ad58-42d8-ba87-476b572377ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate White-Black approval gap\n",
    "if ('White' in approval_rates_df['derived_race'].values) and ('Black or African American' in approval_rates_df['derived_race'].values):\n",
    "    white_pred_rate = approval_rates_df[approval_rates_df['derived_race'] == 'White']['predicted_approval_rate'].iloc[0]\n",
    "    black_pred_rate = approval_rates_df[approval_rates_df['derived_race'] == 'Black or African American']['predicted_approval_rate'].iloc[0]\n",
    "    white_black_gap = white_pred_rate - black_pred_rate\n",
    "    print(f\"White-Black Predicted Approval Rate Gap: {white_black_gap:.4f}\")\n",
    "else:\n",
    "    print(\"Cannot calculate White-Black gap: Missing racial groups.\")\n",
    "    print(\"Races in results:\", approval_rates_df['derived_race'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30565536-a796-4afc-a0d5-a2b8f1d8b0f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efa0988-1dd3-42e0-b3c8-6fa970dc1173",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d71c139-688f-40bd-a553-af48b35f70ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d6b350-853a-4f90-abea-18c9a3382c10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fff82d-fbe8-41ae-9b08-f47e9180fe9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7d32ba-8dda-4f0f-a7ff-c1ec325029a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01b490b-219f-490e-95dc-3808ad67d6ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
